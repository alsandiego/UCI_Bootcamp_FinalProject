{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"created_at\": \"Wed Jul 20 02:34:27 +0000 2016\", \"description\": \"I am Al and I am passionate about technology.\", \"followers_count\": 5, \"friends_count\": 52, \"id\": 755591669194514432, \"id_str\": \"755591669194514432\", \"location\": \"Tustin, CA\", \"name\": \"Al\", \"profile_background_color\": \"000000\", \"profile_background_image_url\": \"http://abs.twimg.com/images/themes/theme1/bg.png\", \"profile_background_image_url_https\": \"https://abs.twimg.com/images/themes/theme1/bg.png\", \"profile_banner_url\": \"https://pbs.twimg.com/profile_banners/755591669194514432/1469041661\", \"profile_image_url\": \"http://pbs.twimg.com/profile_images/755843006062694401/2JikSpJq_normal.jpg\", \"profile_image_url_https\": \"https://pbs.twimg.com/profile_images/755843006062694401/2JikSpJq_normal.jpg\", \"profile_link_color\": \"1B95E0\", \"profile_sidebar_border_color\": \"000000\", \"profile_sidebar_fill_color\": \"000000\", \"profile_text_color\": \"000000\", \"screen_name\": \"alknowstech\", \"status\": {\"created_at\": \"Mon Jul 31 21:38:46 +0000 2017\", \"favorite_count\": 1, \"id\": 892137484921978880, \"id_str\": \"892137484921978880\", \"in_reply_to_screen_name\": \"TechYESCity\", \"in_reply_to_status_id\": 891577872384638976, \"in_reply_to_user_id\": 1021097054, \"lang\": \"en\", \"source\": \"<a href=\\\"http://twitter.com\\\" rel=\\\"nofollow\\\">Twitter Web Client</a>\", \"text\": \"@TechYESCity thanks for the reply.. is it stable enough to OC to 4ghz on 1700? i plan to use AIO cpu cooler\"}, \"statuses_count\": 5}\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkFiles\n",
    "import twitter\n",
    "import os\n",
    "from config import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# initialize api instance\n",
    "twitter_api = twitter.Api(consumer_key=consumer_key,\n",
    "                         consumer_secret=consumer_secret,\n",
    "                         access_token_key=access_token_key,\n",
    "                         access_token_secret=access_token_secret)\n",
    "\n",
    "#print(consumer_key,consumer_secret,access_token_key,access_token_secret)\n",
    "\n",
    "# test authentication\n",
    "print(twitter_api.VerifyCredentials())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Get the default configurations\n",
    "spark.sparkContext._conf.getAll()\n",
    "\n",
    "# Update the default configurations\n",
    "conf = spark.sparkContext._conf.setAll([(\"spark.executor.heartbeatInterval\", \"300000\"),\n",
    "                                       (\"spark.network.timeout\", \"400000\"),('spark.executor.memory', '6g'),\n",
    "                                        ('spark.app.name', 'Spark Updated Conf'),\n",
    "                                        ('spark.executor.cores', '6'), ('spark.cores.max', '6'), \n",
    "                                        ('spark.driver.memory','6g')])\n",
    "\n",
    "# Stop the current Spark Session\n",
    "spark.sparkContext.stop()\n",
    "\n",
    "# Create a Spark Session\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity of the tweet</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity of the tweet                                               text\n",
       "0                      0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1                      0  is upset that he can't update his Facebook by ...\n",
       "2                      0  @Kenichan I dived many times for the ball. Man...\n",
       "3                      0    my whole body feels itchy and like its on fire \n",
       "4                      0  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata140 = os.path.join(\".\",\"trainingandtestdata_sentiment140\",\"training.csv\")\n",
    "\n",
    "train_df = pd.read_csv(traindata140, header=None, usecols=[0,5], names=['polarity of the tweet', 'text'], \n",
    "                       encoding=\"ISO-8859-1\")\n",
    "train_df.head()\n",
    "# (0 = negative, 2 = neutral, 4 = positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|                text|   class|\n",
      "+--------------------+--------+\n",
      "|@stellargirl I lo...|positive|\n",
      "|Reading my kindle...|positive|\n",
      "|Ok, first assesme...|positive|\n",
      "|@kenburbary You'l...|positive|\n",
      "|@mikefish  Fair e...|positive|\n",
      "|@richardebaker no...|positive|\n",
      "|Fuck this economy...|negative|\n",
      "|Jquery is my new ...|positive|\n",
      "|       Loves twitter|positive|\n",
      "|how can you not l...|positive|\n",
      "|Check this video ...| neutral|\n",
      "|@Karoli I firmly ...|negative|\n",
      "|House Corresponde...|positive|\n",
      "|Watchin Espn..Jus...|positive|\n",
      "|dear nike, stop w...|negative|\n",
      "|#lebron best athl...|positive|\n",
      "|I was talking to ...|negative|\n",
      "|i love lebron. ht...|positive|\n",
      "|@ludajuice Lebron...|negative|\n",
      "|@Pmillzz lebron I...|positive|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test Data\n",
    "testdata140 = os.path.join(\".\",\"trainingandtestdata_sentiment140\",\"test.csv\")\n",
    "\n",
    "test_df = pd.read_csv(testdata140, header=None, usecols=[0,5], names=['polarity of the tweet', 'text'], \n",
    "                       encoding=\"ISO-8859-1\")\n",
    "test_df.head()\n",
    "# (0 = negative, 2 = neutral, 4 = positive)\n",
    "\n",
    "conditions_test = [\n",
    "    (test_df['polarity of the tweet'] == 0),\n",
    "    (test_df['polarity of the tweet'] == 2),\n",
    "    (test_df['polarity of the tweet'] == 4)]\n",
    "choices_test = ['negative', 'neutral', 'positive']\n",
    "test_df['class'] = np.select(conditions_test, choices_test)\n",
    "test_df.head()\n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "# convert pandas DF to spark Df\n",
    "spark_df_test = sqlContext.createDataFrame(test_df.iloc[:,1:3])\n",
    "spark_df_test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity of the tweet</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity of the tweet                                               text  \\\n",
       "0                      0  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1                      0  is upset that he can't update his Facebook by ...   \n",
       "2                      0  @Kenichan I dived many times for the ball. Man...   \n",
       "3                      0    my whole body feels itchy and like its on fire    \n",
       "4                      0  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "      class  \n",
       "0  negative  \n",
       "1  negative  \n",
       "2  negative  \n",
       "3  negative  \n",
       "4  negative  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions = [\n",
    "    (train_df['polarity of the tweet'] == 0),\n",
    "    (train_df['polarity of the tweet'] == 2),\n",
    "    (train_df['polarity of the tweet'] == 4)]\n",
    "choices = ['negative', 'neutral', 'positive']\n",
    "train_df['class'] = np.select(conditions, choices)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|                text|   class|\n",
      "+--------------------+--------+\n",
      "|@switchfoot http:...|negative|\n",
      "|is upset that he ...|negative|\n",
      "|@Kenichan I dived...|negative|\n",
      "|my whole body fee...|negative|\n",
      "|@nationwideclass ...|negative|\n",
      "|@Kwesidei not the...|negative|\n",
      "|         Need a hug |negative|\n",
      "|@LOLTrish hey  lo...|negative|\n",
      "|@Tatiana_K nope t...|negative|\n",
      "|@twittera que me ...|negative|\n",
      "|spring break in p...|negative|\n",
      "|I just re-pierced...|negative|\n",
      "|@caregiving I cou...|negative|\n",
      "|@octolinz16 It it...|negative|\n",
      "|@smarrison i woul...|negative|\n",
      "|@iamjazzyfizzle I...|negative|\n",
      "|Hollis' death sce...|negative|\n",
      "|about to file taxes |negative|\n",
      "|@LettyA ahh ive a...|negative|\n",
      "|@FakerPattyPattz ...|negative|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "# convert pandas DF to spark Df\n",
    "spark_df = sqlContext.createDataFrame(train_df.iloc[:,1:3])\n",
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+------+\n",
      "|                text|   class|length|\n",
      "+--------------------+--------+------+\n",
      "|@stellargirl I lo...|positive|   111|\n",
      "|Reading my kindle...|positive|    58|\n",
      "|Ok, first assesme...|positive|    58|\n",
      "|@kenburbary You'l...|positive|   140|\n",
      "|@mikefish  Fair e...|positive|    75|\n",
      "|@richardebaker no...|positive|    67|\n",
      "|Fuck this economy...|negative|    61|\n",
      "|Jquery is my new ...|positive|    29|\n",
      "|       Loves twitter|positive|    13|\n",
      "|how can you not l...|positive|    57|\n",
      "|Check this video ...| neutral|   101|\n",
      "|@Karoli I firmly ...|negative|   140|\n",
      "|House Corresponde...|positive|   106|\n",
      "|Watchin Espn..Jus...|positive|    98|\n",
      "|dear nike, stop w...|negative|    95|\n",
      "|#lebron best athl...|positive|   135|\n",
      "|I was talking to ...|negative|   136|\n",
      "|i love lebron. ht...|positive|    34|\n",
      "|@ludajuice Lebron...|negative|    74|\n",
      "|@Pmillzz lebron I...|positive|    27|\n",
      "+--------------------+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import length\n",
    "# Create a length column to be used as a future feature \n",
    "data_df = spark_df_test.withColumn('length', length(spark_df_test['text']))\n",
    "data_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Transformations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer\n",
    "# Create all the features to the data set\n",
    "pos_neg_to_num = StringIndexer(inputCol='class',outputCol='label')\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"token_text\")\n",
    "stopremove = StopWordsRemover(inputCol='token_text',outputCol='stop_tokens')\n",
    "hashingTF = HashingTF(inputCol=\"token_text\", outputCol='hash_token')\n",
    "idf = IDF(inputCol='hash_token', outputCol='idf_token')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vector\n",
    "\n",
    "# Create feature vectors\n",
    "clean_up = VectorAssembler(inputCols=['idf_token', 'length'], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a and run a data processing Pipeline\n",
    "from pyspark.ml import Pipeline\n",
    "data_prep_pipeline = Pipeline(stages=[pos_neg_to_num, tokenizer, stopremove, hashingTF, idf, clean_up])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the pipeline\n",
    "cleaner = data_prep_pipeline.fit(data_df)\n",
    "cleaned = cleaner.transform(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|   class|length|label|          token_text|         stop_tokens|          hash_token|           idf_token|            features|\n",
      "+--------------------+--------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|@stellargirl I lo...|positive|   111|  0.0|[@stellargirl, i,...|[@stellargirl, lo...|(262144,[7877,158...|(262144,[7877,158...|(262145,[7877,158...|\n",
      "+--------------------+--------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show label and resulting features\n",
    "cleaned.select(['label', 'features']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "# Break data down into a training set and a testing set\n",
    "# training, testing = cleaned.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Create a Naive Bayes model and fit training data\n",
    "nb = NaiveBayes()\n",
    "predictor = nb.fit(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tranform the model with the testing data\n",
    "test_results = predictor.transform(testing)\n",
    "test_results.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Class Evaluator for a cleaner description\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "acc_eval = MulticlassClassificationEvaluator()\n",
    "acc = acc_eval.evaluate(test_results)\n",
    "print(\"Accuracy of model at predicting reviews was: %f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nteract": {
   "version": "0.11.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
