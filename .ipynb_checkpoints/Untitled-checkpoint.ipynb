{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processors:  16\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "print(\"Number of processors: \", mp.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"created_at\": \"Wed Jul 20 02:34:27 +0000 2016\", \"description\": \"I am Al and I am passionate about technology.\", \"followers_count\": 5, \"friends_count\": 52, \"id\": 755591669194514432, \"id_str\": \"755591669194514432\", \"location\": \"Tustin, CA\", \"name\": \"Al\", \"profile_background_color\": \"000000\", \"profile_background_image_url\": \"http://abs.twimg.com/images/themes/theme1/bg.png\", \"profile_background_image_url_https\": \"https://abs.twimg.com/images/themes/theme1/bg.png\", \"profile_banner_url\": \"https://pbs.twimg.com/profile_banners/755591669194514432/1469041661\", \"profile_image_url\": \"http://pbs.twimg.com/profile_images/755843006062694401/2JikSpJq_normal.jpg\", \"profile_image_url_https\": \"https://pbs.twimg.com/profile_images/755843006062694401/2JikSpJq_normal.jpg\", \"profile_link_color\": \"1B95E0\", \"profile_sidebar_border_color\": \"000000\", \"profile_sidebar_fill_color\": \"000000\", \"profile_text_color\": \"000000\", \"screen_name\": \"alknowstech\", \"status\": {\"created_at\": \"Mon Jul 31 21:38:46 +0000 2017\", \"favorite_count\": 1, \"id\": 892137484921978880, \"id_str\": \"892137484921978880\", \"in_reply_to_screen_name\": \"TechYESCity\", \"in_reply_to_status_id\": 891577872384638976, \"in_reply_to_user_id\": 1021097054, \"lang\": \"en\", \"source\": \"<a href=\\\"http://twitter.com\\\" rel=\\\"nofollow\\\">Twitter Web Client</a>\", \"text\": \"@TechYESCity thanks for the reply.. is it stable enough to OC to 4ghz on 1700? i plan to use AIO cpu cooler\"}, \"statuses_count\": 5}\n"
     ]
    }
   ],
   "source": [
    "import twitter\n",
    "import os\n",
    "from config import *\n",
    "\n",
    "# initialize api instance\n",
    "twitter_api = twitter.Api(consumer_key=consumer_key,\n",
    "                         consumer_secret=consumer_secret,\n",
    "                         access_token_key=access_token_key,\n",
    "                         access_token_secret=access_token_secret)\n",
    "\n",
    "#print(consumer_key,consumer_secret,access_token_key,access_token_secret)\n",
    "\n",
    "# test authentication\n",
    "print(twitter_api.VerifyCredentials())\n",
    "# print(twitter_api.GetStatus(126402758403305000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildTestSet(search_keyword):\n",
    "    try:\n",
    "        tweets_fetched = twitter_api.GetSearch(search_keyword, count = 100)\n",
    "        \n",
    "        print(\"Fetched \" + str(len(tweets_fetched)) + \" tweets for the term \" + search_keyword)\n",
    "        \n",
    "        return [{\"text\":status.text, \"label\":None} for status in tweets_fetched]\n",
    "    except:\n",
    "        print(\"Unfortunately, something went wrong..\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a search keyword:ice cream\n",
      "Fetched 100 tweets for the term ice cream\n",
      "[{'text': '\"I hope he learned his lesson.\"\\n\\nSurveillance video shows ice cream shop owner grab her gun and open fire, scaring… https://t.co/tVZzSeq22C', 'label': None}, {'text': 'When I was 12, I was walking by an ice cream shop when a Palestinian suicide bomber blew it up. Jewish granny &amp; her… https://t.co/egKUQeOipG', 'label': None}, {'text': 'Ice Cream Sandwich Cake\\nShop this recipe in our Tasty iOS app:\\nhttps://t.co/rwVBJ3CZn2 https://t.co/Htbwy5y5xx', 'label': None}, {'text': 'Parked in front of an ice cream shop, shoveling hibachi bowl in my face and I make direct eye contact with the person inside the shop', 'label': None}, {'text': 'someone bring me ice cream pls', 'label': None}, {'text': 'RT @Coleyped12: Get you those kind of friends who... \\n1) point you to Jesus \\n2) remind you of your worth and that you are worth being pursu…', 'label': None}, {'text': 'RT @MagnumIceCream: Discover the newest chocolate, Ruby. New Magnum Ruby Mini decadently pairs Ruby Cacao and sweet cream ice cream.', 'label': None}, {'text': 'RT @MaywardIsLIT: Alam nyo ba ang masarap na kacombination ng @LaysPhilippines ? Eh di ice cream... lalo na pag @SelectaCornetto ! Both end…', 'label': None}, {'text': 'RT @BTSTINYS: therapist: a guy eating ice cream can’t hurt you \\n\\nthe guy eating the ice cream: https://t.co/VKrIMncYyy', 'label': None}, {'text': 'Coconut ice cream anyone? What it lacks in dairy and refined sugar it makes up with fats found in natural oils and… https://t.co/U9GVC4ObQw', 'label': None}]\n"
     ]
    }
   ],
   "source": [
    "# test search function\n",
    "search_term = input(\"Enter a search keyword:\")\n",
    "testDataSet = buildTestSet(search_term)\n",
    "\n",
    "print(testDataSet[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildTrainingSet(corpusFile, tweetDataFile):\n",
    "    import csv\n",
    "    import time\n",
    "    \n",
    "    corpus = []\n",
    "    \n",
    "    with open(corpusFile,'r') as csvfile:\n",
    "        lineReader = csv.reader(csvfile,delimiter=',', quotechar=\"\\\"\")\n",
    "        for row in lineReader:\n",
    "            corpus.append({\"tweet_id\":row[2], \"label\":row[1], \"topic\":row[0]})\n",
    "            \n",
    "    rate_limit = 180\n",
    "    sleep_time = 900/180\n",
    "    \n",
    "#     print(corpus)\n",
    "    trainingDataSet = []\n",
    "    \n",
    "    for tweet in corpus:\n",
    "        try:\n",
    "            status = twitter_api.GetStatus(tweet[\"tweet_id\"])\n",
    "#             print(\"Tweet fetched\" + status.text+\" \"+tweet[\"tweet_id\"])\n",
    "            print(tweet[\"tweet_id\"])\n",
    "            tweet[\"text\"] = status.text\n",
    "            trainingDataSet.append(tweet)\n",
    "            time.sleep(sleep_time) \n",
    "        except: \n",
    "            continue\n",
    "    # now we write them to the empty CSV file\n",
    "    with open(tweetDataFile,'wb') as csvfile:\n",
    "        linewriter = csv.writer(csvfile,delimiter=',',quotechar=\"\\\"\")\n",
    "        for tweet in trainingDataSet:\n",
    "            try:\n",
    "                linewriter.writerow([tweet[\"tweet_id\"], tweet[\"text\"], tweet[\"label\"], tweet[\"topic\"]])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    return trainingDataSet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126415614616154112\n",
      "126402758403305474\n",
      "126379685453119488\n",
      "126377656416612353\n",
      "126373779483004928\n",
      "a bytes-like object is required, not 'str'\n",
      "a bytes-like object is required, not 'str'\n",
      "a bytes-like object is required, not 'str'\n",
      "a bytes-like object is required, not 'str'\n",
      "a bytes-like object is required, not 'str'\n",
      "[{'tweet_id': '126415614616154112', 'label': 'positive', 'topic': 'apple', 'text': 'Now all @Apple has to do is get swype on the iphone and it will be crack. Iphone that is'}, {'tweet_id': '126402758403305474', 'label': 'positive', 'topic': 'apple', 'text': \"Hilarious @youtube video - guy does a duet with @apple 's Siri. Pretty much sums up the love affair! http://t.co/8ExbnQjY\"}, {'tweet_id': '126379685453119488', 'label': 'positive', 'topic': 'apple', 'text': 'The 16 strangest things Siri has said so far. I am SOOO glad that @Apple gave Siri a sense of humor! http://t.co/TWAeUDBp via @HappyPlace'}, {'tweet_id': '126377656416612353', 'label': 'positive', 'topic': 'apple', 'text': 'Great up close & personal event @Apple tonight in Regent St store!'}, {'tweet_id': '126373779483004928', 'label': 'positive', 'topic': 'apple', 'text': 'From which companies do you experience the best customer service aside from @zappos and @apple?'}]\n"
     ]
    }
   ],
   "source": [
    "corpusFile = os.path.join(\".\", \"corpus20.csv\")\n",
    "tweetDataFile = os.path.join(\".\", \"tweetDataFile.csv\")\n",
    "\n",
    "trainingData = buildTrainingSet(corpusFile, tweetDataFile)\n",
    "print(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "traindata140 = os.path.join(\".\",\"trainingandtestdata_sentiment140\",\"training.1600000.processed.noemoticon.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the csv file command\n",
    "train_df = pd.read_csv(traindata140, header=None, usecols=[0,1,5], names=['polarity of the tweet', 'tweet_id','tweet'], encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity of the tweet</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity of the tweet    tweet_id  \\\n",
       "0                      0  1467810369   \n",
       "1                      0  1467810672   \n",
       "2                      0  1467810917   \n",
       "3                      0  1467811184   \n",
       "4                      0  1467811193   \n",
       "\n",
       "                                               tweet  \n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1  is upset that he can't update his Facebook by ...  \n",
       "2  @Kenichan I dived many times for the ball. Man...  \n",
       "3    my whole body feels itchy and like its on fire   \n",
       "4  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()\n",
    "# (0 = negative, 2 = neutral, 4 = positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity of the tweet</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity of the tweet    tweet_id  \\\n",
       "0                      0  1467810369   \n",
       "1                      0  1467810672   \n",
       "2                      0  1467810917   \n",
       "3                      0  1467811184   \n",
       "4                      0  1467811193   \n",
       "\n",
       "                                               tweet     label  \n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  negative  \n",
       "1  is upset that he can't update his Facebook by ...  negative  \n",
       "2  @Kenichan I dived many times for the ball. Man...  negative  \n",
       "3    my whole body feels itchy and like its on fire   negative  \n",
       "4  @nationwideclass no, it's not behaving at all....  negative  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions = [\n",
    "    (train_df['polarity of the tweet'] == 0),\n",
    "    (train_df['polarity of the tweet'] == 2),\n",
    "    (train_df['polarity of the tweet'] == 4)]\n",
    "choices = ['negative', 'neutral', 'positive']\n",
    "train_df['label'] = np.select(conditions, choices)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ls = train_df.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'polarity of the tweet': 0, 'tweet_id': 1467810369, 'tweet': \"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\", 'label': 'negative'}, {'polarity of the tweet': 0, 'tweet_id': 1467810672, 'tweet': \"is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!\", 'label': 'negative'}, {'polarity of the tweet': 0, 'tweet_id': 1467810917, 'tweet': '@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds', 'label': 'negative'}, {'polarity of the tweet': 0, 'tweet_id': 1467811184, 'tweet': 'my whole body feels itchy and like its on fire ', 'label': 'negative'}, {'polarity of the tweet': 0, 'tweet_id': 1467811193, 'tweet': \"@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there. \", 'label': 'negative'}, {'polarity of the tweet': 0, 'tweet_id': 1467811372, 'tweet': '@Kwesidei not the whole crew ', 'label': 'negative'}, {'polarity of the tweet': 0, 'tweet_id': 1467811592, 'tweet': 'Need a hug ', 'label': 'negative'}, {'polarity of the tweet': 0, 'tweet_id': 1467811594, 'tweet': \"@LOLTrish hey  long time no see! Yes.. Rains a bit ,only a bit  LOL , I'm fine thanks , how's you ?\", 'label': 'negative'}, {'polarity of the tweet': 0, 'tweet_id': 1467811795, 'tweet': \"@Tatiana_K nope they didn't have it \", 'label': 'negative'}, {'polarity of the tweet': 0, 'tweet_id': 1467812025, 'tweet': '@twittera que me muera ? ', 'label': 'negative'}]\n"
     ]
    }
   ],
   "source": [
    "print(train_ls[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/al.sandiego/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'tweet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-ba19389845db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mtweetProcessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPreProcessTweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mpreprocessedTrainingSet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweetProcessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessTweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mpreprocessedTestSet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweetProcessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessTweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestDataSet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-ba19389845db>\u001b[0m in \u001b[0;36mprocessTweets\u001b[0;34m(self, list_of_tweets)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprocessedTweets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_of_tweets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mprocessedTweets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_processTweet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tweet\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mprocessedTweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'tweet'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation \n",
    "from nltk.corpus import stopwords \n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "class PreProcessTweets:\n",
    "    def __init__(self):\n",
    "        self._stopwords = set(stopwords.words('english') + list(punctuation) + ['AT_USER','URL'])\n",
    "        \n",
    "    def processTweets(self, list_of_tweets):\n",
    "        processedTweets=[]\n",
    "        for tweet in list_of_tweets:\n",
    "            processedTweets.append((self._processTweet(tweet[\"tweet\"]),tweet[\"label\"]))\n",
    "        return processedTweets\n",
    "    \n",
    "    def _processTweet(self, tweet):\n",
    "        tweet = tweet.lower() # convert text to lower-case\n",
    "        tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', 'URL', tweet) # remove URLs\n",
    "        tweet = re.sub('@[^\\s]+', 'AT_USER', tweet) # remove usernames\n",
    "        tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet) # remove the # in #hashtag\n",
    "        tweet = word_tokenize(tweet) # remove repeated characters (helloooooooo into hello)\n",
    "        return [word for word in tweet if word not in self._stopwords]\n",
    "    \n",
    "tweetProcessor = PreProcessTweets()\n",
    "preprocessedTrainingSet = tweetProcessor.processTweets(train_ls)\n",
    "preprocessedTestSet = tweetProcessor.processTweets(testDataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "\n",
    "def buildVocabulary(preprocessedTrainingData):\n",
    "    all_words = []\n",
    "    \n",
    "    for (words, sentiment) in preprocessedTrainingData:\n",
    "        all_words.extend(words)\n",
    "\n",
    "    wordlist = nltk.FreqDist(all_words)\n",
    "    word_features = wordlist.keys()\n",
    "    \n",
    "    return word_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_features(tweet):\n",
    "    tweet_words = set(tweet)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains(%s)' % word] = (word in tweet_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_features = buildVocabulary(preprocessedTrainingData)\n",
    "trainingFeatures = nltk.classify.apply_features(extract_features, preprocessedTrainingData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBayesClassifier = nltk.NaiveBayesClassifier.train(trainingFeatures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBResultLabels = [NBayesClassifier.classify(extract_features(tweet[0])) for tweet in preprocessedTestDataSet]\n",
    "\n",
    "# get the majority vote\n",
    "if NBResultLabels.count('positive') > NBResultLabels.count('negative'):\n",
    "    print(\"Overall Positive Sentiment\")\n",
    "    print(\"Positive Sentiment Percentage = \" + str(100*NBResultLabels.count('positive')/len(NBResultLabels)) + \"%\")\n",
    "else: \n",
    "    print(\"Overall Negative Sentiment\")\n",
    "    print(\"Negative Sentiment Percentage = \" + str(100*NBResultLabels.count('negative')/len(NBResultLabels)) + \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
